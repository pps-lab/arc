
import ml

from datasets import load_dataset
from transformers import BertModel, BertForSequenceClassification, BertTokenizer
import torch

# Load pre-trained BERT model and tokenizer
# model_name = 'prajjwal1/bert-tiny-mnli'  # You can choose other versions of BERT like 'bert-large-uncased'
# model_name = 'M-FAC/bert-tiny-finetuned-qnli'
model_name = 'gchhablani/bert-base-cased-finetuned-qnli'

# Load the tokenizer
tokenizer = BertTokenizer.from_pretrained(model_name)

# Load the BERT model
model = BertForSequenceClassification.from_pretrained(model_name)
max_length = 128

ml.set_n_threads(24)

#
task_name = 'qnli'
dataset = load_dataset('glue', task_name)

# Access the evaluation dataset
validation = dataset['validation']

n_samples_to_run = 1


# # # Load the MNLI dataset
# mnli_dataset = load_dataset('multi_nli')
# #
# # # Access the evaluation datasets
# mnli_validation_matched = mnli_dataset['validation_matched']
# mnli_validation_mismatched = mnli_dataset['validation_mismatched']

print("mnli_validation_matched", validation.shape)

task_to_keys = {
    "cola": ("sentence", None),
    "mnli": ("premise", "hypothesis"),
    "mrpc": ("sentence1", "sentence2"),
    "qnli": ("question", "sentence"),
    "qqp": ("question1", "question2"),
    "rte": ("sentence1", "sentence2"),
    "sst2": ("sentence", None),
    "stsb": ("sentence1", "sentence2"),
    "wnli": ("sentence1", "sentence2"),
}

# Function to tokenize the dataset
def tokenized_fn(example):
    sentence1_key, sentence2_key = task_to_keys[task_name]
    args = (
        (example[sentence1_key],) if sentence2_key is None else (example[sentence1_key], example[sentence2_key])
    )
    print("ARGS", args)
    encoded_input = tokenizer(*args, truncation=True, padding='max_length', max_length=max_length)
    print("ECODED", encoded_input)
    return encoded_input

def embed_fn(example):
    import numpy as np
    embedding_list = []
    # for input_id, token_type_ids in zip(example["input_ids"], example["token_type_ids"]):
    #     # embedding_list.append(torch.ones([8]))
    print(torch.tensor(example["input_ids"]))
    print("token_Type_ids", torch.tensor(example["token_type_ids"]))
    #     embedding = model.bert.embeddings(torch.tensor(input_id), token_type_ids=torch.tensor(token_type_ids)).detach()
    #     embedding_list.append(embedding)

    embedding = model.bert.embeddings(torch.tensor(example["input_ids"]), token_type_ids=torch.tensor(example["token_type_ids"])).detach()
    return { 'embedding': embedding }

# Tokenize the validation datasets
# with mnli_validation_matched.formatted_as("torch", ["input_ids", "token_type_ids"]):
tokenized_validation_matched_pt = validation.take(n_samples_to_run).map(tokenized_fn, batched=True)
tokenized_validation = tokenized_validation_matched_pt.map(embed_fn, batched=True)
# with mnli_validation_mismatched.formatted_as("torch", ["input_ids", "token_type_ids"]):

print(tokenized_validation, type(tokenized_validation))

# get performance on PT model
def get_predictions(model, tokenized_dataset):
    model.eval()
    predictions = []
    with torch.no_grad():
        for i in range(n_samples_to_run):
            example = tokenized_dataset[i]
            inputs = {key: torch.tensor([val]) for key, val in example.items() if key in ['input_ids', 'attention_mask', 'token_type_ids']}
            print("PT Inputs", inputs)
            outputs = model(**inputs)
            logits = outputs.logits
            # predicted_class = torch.argmax(logits, dim=-1).item()
            probabilities = torch.softmax(logits, dim=-1)
            predictions.append(probabilities)
    return predictions

activation_list = []
def get_activation(name):
    def hook(model, input, output):
        activation_list.append((name, output[0].detach()))
    return hook
for layer_id, bert_layer in enumerate(model.bert.encoder.layer):
    bert_layer.register_forward_hook(get_activation(f'bert.encoder.layer.{layer_id}'))

pt_predictions = get_predictions(model, tokenized_validation_matched_pt)
pt_predictions_top = torch.argmax(torch.cat(pt_predictions), dim=-1)
print_ln("PT Predictions %s", str(pt_predictions))
print_ln("PT Predictions Top %s", str(pt_predictions_top))
print("Running n_samples_to_run", n_samples_to_run)

print("Bert activations ", activation_list)
def build_sfix_tensor(dataset):
    with dataset.formatted_as("torch", ["embedding", "label"]):
        tensor_embedding = torch.concat(list(map(lambda x: x['embedding'], dataset.iter(batch_size=1))))
        tensor_label = torch.concat(list(map(lambda x: x['label'], dataset.iter(batch_size=1))))

        # one-hot encode tensor_label
        tensor_label = torch.nn.functional.one_hot(tensor_label, num_classes=-1)

        tensor_embedding_sfix = sfix.input_tensor_via(0, tensor_embedding.numpy())
        tensor_label_sfix = sint.input_tensor_via(0, tensor_label.numpy())

        return tensor_embedding_sfix, tensor_label_sfix

import numpy
def get_predictions(model, test_x, test_y):

    # print_ln("Embeddings %s", test_x.reveal_nested())

    layers = ml.layers_from_torch(model, test_x.shape, input_via=0, batch_size=1) # set batch size bigger?
    optimizer = ml.Optimizer(layers)
    # optimizer.reset()
    # optimizer.print_random_update = True
    pt_predictions_tensor_spdz = sfix.input_tensor_via(0, numpy.array(numpy.concatenate(pt_predictions)))
    # print_ln("PT Predictions %s %s", pt_predictions_tensor_spdz.reveal_nested(),  numpy.array(numpy.concatenate(pt_predictions)))
    pred = optimizer.reveal_correctness(test_x, pt_predictions_tensor_spdz, batch_size=1)
    print_ln("PRED %s", pred)

    # pred = optimizer.eval(test_x)
    # for l, p in zip(test_y.reveal_nested(), pred.reveal_nested()):
    #     print_str("%s == ", l)
    #     print_str("%s, ", p)

    # pred = optimizer.eval(test_x, batch_size=)
    # for l, p in zip(pt_predictions_top, pred.reveal_nested()):
    #     print_str("%s == ", l)
    #     print_str("%s, ", p)
    # print_ln(" ")

    # compare the values in activation_list with the values in the layers
    # relevant_model_layers = optimizer.layers[:-4]
    # print("relevant_model_layers", relevant_model_layers)
    # for pt_values, relevant_model_layer in zip(activation_list, relevant_model_layers):
    #     # compute diff
    #     pt_at_runtime = sfix.input_tensor_via(0, pt_values[1].numpy()).get_vector().reveal()
    #     layer_output = relevant_model_layer.Y[0].get_vector().reveal()
    #
    #     # display first 3 of both
    #     print_ln("pt_at_runtime %s", pt_at_runtime[:8])
    #     print_ln("layer_output  %s", layer_output[:8])
    #     # compute diff
    #     diff = sum((pt_at_runtime - layer_output) ** 2)
    #     print_ln("diff %s", diff)


def run(dataset):
    test_x, test_y = build_sfix_tensor(dataset)
    get_predictions(model, test_x, test_y)

# sfix.round_nearest = True
program.use_trunc_pr = False
# sfix.set_precision(18)
# cfix.set_precision(18)
# cfix.set_precision(f=32, k=62)
# sfix.set_precision(f=32, k=62)
# cfix.set_precision(f=14, k=31)
# sfix.set_precision(f=14, k=31)

print("Running tokenized_validation_matched")
run(tokenized_validation)

# print("Running tokenized_validation_mismatched")
# run(tokenized_validation_mismatched)
