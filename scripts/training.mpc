from Compiler.script_utils import output_utils

from Compiler.script_utils.data import data
from Compiler.script_utils.data import AbstractInputLoader


from Compiler import ml
from Compiler import library

from Compiler.script_utils.audit import shap

from Compiler.script_utils import config, timers




class TrainingConfig(config.BaseAuditModel):
    n_epochs: int = 1 # -1 = all

program.options_from_args()
cfg = config.from_program_args(program.args, TrainingConfig)

if not cfg.emulate:
    pass
    # program.use_trunc_pr = cfg.trunc_pr
    # program.use_edabits = True
    # program.use_split(4)

# program.use_edabit(False)
# program.use_dabit = False
# program.use_split(3)

# program.set_bit_length(32)

ml.set_n_threads(cfg.n_threads)

library.start_timer(timer_id=timers.TIMER_LOAD_DATA)
input_loader: AbstractInputLoader = data.get_input_loader(dataset=cfg.dataset, audit_trigger_idx=cfg.audit_trigger_idx,
                                                                    batch_size=cfg.batch_size, debug=cfg.debug, emulate=cfg.emulate, consistency_check=cfg.consistency_check,
                                                          )
library.stop_timer(timer_id=timers.TIMER_LOAD_DATA)


library.start_timer(timer_id=timers.TIMER_TRAINING)

# eval here
train_samples, train_labels = input_loader.train_dataset() # train dataset in case we dont have test dataset


model = input_loader.model()
model.summary()

model.fit(
    train_samples,
    train_labels,
    epochs=int(cfg.n_epochs),
    batch_size=128,
    program=program
)
# prediction_results = model.eval(inf_samples, batch_size=min(cfg.batch_size, cfg.n_samples))
# n_correct, avg_loss = model.reveal_correctness(data=inf_samples, truth=inf_labels, batch_size=input_loader.batch_size(), running=True)
# print_ln("  n_correct=%s  n_samples=%s  avg_loss=%s", n_correct, len(inf_samples), avg_loss)

library.stop_timer(timer_id=timers.TIMER_TRAINING)

# if cfg.debug:
#     print_ln(prediction_results.reveal(), inf_labels.reveal())
