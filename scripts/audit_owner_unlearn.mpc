from Compiler.script_utils import output_utils

from Compiler.script_utils.data import data


from Compiler import ml
from Compiler import library

from Compiler.script_utils.audit import owner_unlearn

from Compiler.script_utils import config

program.options_from_args()
program.use_trunc_pr = True
program.use_edabits = True


class AuditConfig(config.BaseAuditModel):
    learning_rate: float = 0.01
    mod_zscore_threshold: float = 2.5
    n_unlearn_epochs: int = 1


cfg = config.from_program_args(program.args, AuditConfig)

ml.set_n_threads(cfg.n_threads)

input_loader = data.get_input_loader(dataset=cfg.dataset, batch_size=cfg.batch_size, debug=cfg.debug, emulate=cfg.emulate)

library.start_timer(timer_id=100)

result = owner_unlearn.audit(input_loader, config=cfg, debug=cfg.debug)


# TODO: should probably think about the output here -> can we define a structured output form that
#       applies to all audit functions
#       maybe could distinguish between "reveal" output vs "debugging output"
# Party Level: [{"party": 3, "score": 0.9}], also []
# Sample Level: [{"party": 3, "sample_id": 1, "score": 0.7}]
# Feature Level: [{"feature_id": "col1", "score": 0.9}]  -> this would be more complex for some feature audit methods

library.stop_timer(timer_id=100)


for k, v in result.items():
    output_utils.output_value(name=k, value=v, repeat=False)
