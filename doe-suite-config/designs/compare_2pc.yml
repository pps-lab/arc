$SUITE_VARS$:
  sleep_time: 2.0 # TODO [hly] can remove (also from experiment runner) as it does not have any effect
  _python_pre: "export PYTHONPATH={{ exp_code_dir }}/utils && . {{ exp_code_dir }}/.venv/bin/activate"
  _python_path: "[% my_run._python_pre %] && {{ exp_code_dir }}/.venv/bin/python"
  cmd: "[% my_run._python_path %] -m  python_utils.scripts.experiment_runner --player-number <PLAYER-ID> --sleep-time [% my_run.sleep_time %]"

twopc:
  n_repetitions: 1
  host_types:
    compute:
      n: 2
      check_status: True
      init_roles:
        - setup-base
#        - setup-network-delay # adjust latency + bandwidth limit -> doe-suite-config/roles/setup-network-delay/vars/main.yml
        - download-dataset # re-enable for fresh install
      $CMD$:
      - main: "[% my_run.cmd | replace('<PLAYER-ID>', 0) %]"
      - main: "[% my_run.cmd | replace('<PLAYER-ID>', 1) %]"

  base_experiment:
    mpc:
      player_0_hostname: "[% exp_host_lst | json_query('[?host_type==`compute`].private_dns_name') | default(['<UNDEFINED-DNS>'], true) | first %]"
      abs_path_to_code_dir: "{{ exp_code_dir }}"
      player_count: 2
      protocol_setup:
        $FACTOR$: ["mascot-party", "lowgear-party", "highgear-party"]

      compiler_args: ['-F', '64', '-C', '--budget', '10000']
#        $FACTOR$: [ "{{ ['-F', '64', '-C', '--budget', '10000'] }}", "{{ ['-F', '64', '-Y', '-C', '--budget', '10000'] }}" ]
#        $FACTOR$: [['-F', '64', '-C', '--budget', '10000'], ['-F', '64', '-Y', '-C', '--budget', '10000']]

      script_name: "torch_camel_regression_predict"

      script_args:
        debug: False  # for a final benchmarking run, can also use `debug: False`, this should then only release no secret info
        emulate: False
        dataset: "xx" # not used
        trunc_pr: False

        # in a network with latency, a high batch size for ml.py is key to a good performance (60k raised insufficient memory error)
        batch_size: 128 #1024 #256 # was 128 before   # 60000 -> insufficient memory
        n_threads: 8 #128 #64 # TODO before was 32 -> see if this helps (128 raises too many files runtime error)

        # inference specific
        n_samples: 40

      stage: # "compile" in run and then in next run "run"
        $FACTOR$: [compile, run] # ensure that this is last factor

#sevenpc:
#  n_repetitions: 1
#  host_types:
#    compute:
#      n: 7
#      check_status: True
#      init_roles:
#        - setup-base
#        #        - setup-network-delay # adjust latency + bandwidth limit -> doe-suite-config/roles/setup-network-delay/vars/main.yml
#        - download-dataset # re-enable for fresh install
#      $CMD$:
#        - main: "[% my_run.cmd | replace('<PLAYER-ID>', 0) %]"
#        - main: "[% my_run.cmd | replace('<PLAYER-ID>', 1) %]"
#        - main: "[% my_run.cmd | replace('<PLAYER-ID>', 2) %]"
#        - main: "[% my_run.cmd | replace('<PLAYER-ID>', 3) %]"
#        - main: "[% my_run.cmd | replace('<PLAYER-ID>', 4) %]"
#        - main: "[% my_run.cmd | replace('<PLAYER-ID>', 5) %]"
#        - main: "[% my_run.cmd | replace('<PLAYER-ID>', 6) %]"
#
#  base_experiment:
#    mpc:
#      player_0_hostname: "[% exp_host_lst | json_query('[?host_type==`compute`].private_dns_name') | default(['<UNDEFINED-DNS>'], true) | first %]"
#      abs_path_to_code_dir: "{{ exp_code_dir }}"
#      player_count: 7
#      protocol_setup: "mascot-party"
#
#      compiler_args: ['-F', "64", '-C', '--budget', '10000'] #'100000000'] # budget was '1000000'1million # also look at B 5 -> cannot be used together with R
#
#      script_name: "torch_camel_regression_predict"
#
#      script_args:
#        debug: False  # for a final benchmarking run, can also use `debug: False`, this should then only release no secret info
#        emulate: False
#        dataset: "xx" # not used
#        trunc_pr: False
#
#        # in a network with latency, a high batch size for ml.py is key to a good performance (60k raised insufficient memory error)
#        batch_size: 128 #1024 #256 # was 128 before   # 60000 -> insufficient memory
#        n_threads: 8 #128 #64 # TODO before was 32 -> see if this helps (128 raises too many files runtime error)
#
#        # inference specific
#        n_samples: 240
#
#      stage: # "compile" in run and then in next run "run"
#        $FACTOR$: [compile, run] # ensure that this is last factor

$ETL$:
  extract_mpspdz:
    experiments: "*"
    extractors:
      MpSpdzStderrExtractor:  {}
      MpSpdzResultExtractor: {}
      IgnoreExtractor: {}
    transformers: []
    loaders:
      CsvSummaryLoader:
        output_dir: etl_results